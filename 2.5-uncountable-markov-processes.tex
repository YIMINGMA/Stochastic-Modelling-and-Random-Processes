\section[Uncountable Markov Processes]{Markov Processes with $S = \mbb{R}$}

Suppose $X: T \mapsto \mbb{R}$, where $T$ can be $\mbb{Z}$ or $\mbb{R}$.

\begin{definition}[Markov Processes]
    $\{X(t): t \in T\}$ is a \textbf{Markov Processes} if it satisfies the Markov property

    \begin{equation*}
        \Prob [X(t_{n+1}) \in A | X(t_n) = s_n, \cdots, X(t_1) = s_1] = \Prob [X(t_{n+1}) \in A | X(t_n) = s_n],
    \end{equation*}

    where $A \subset \mbb{R}$ and $t_{n+1} > t_n > \cdots > t_1$.
\end{definition}

\begin{remark}
    There is a technical problem in the definition. The conditional probability is not well defined, since random variables $X_{t_n}, \cdots, X(t_1)$ now take values in $\mbb{R}$, and the probability that they take particular values is $0$. This will not be a problem if we restrict to any choice of interpretation of conditional probability such that 

    \begin{equation*}
        \Prob[X(t) \in A] = \int \Prob[X(t) \in A | X(0) = x] \dif \Prob [X(0) \le x] \qquad \text{(a Stieltjes integral)}.
    \end{equation*}
\end{remark}

\begin{definition}[Homogeneity]
    A Markov process is \textbf{homoegeneous} if 

    \begin{equation*}
        \Prob [X(t) \in A | X(t') = s] = \Prob [X(t-t') \in A | X(0) = s].
    \end{equation*}
\end{definition}

It is unlikely that $\Prob [X(t) = y | X(0) = x] > 0$, so instead we specify $\Prob [X(t) \in A | X(0) = x]$ for any measurable set $A \subset \mbb{R}$ as 

\begin{equation*}
    \int_A p_t(x,y) \dif y
\end{equation*}

for a transition density $p_t(\cdot, \cdot)$.

\begin{definition}[Transition Densities]
    A \textbf{transition probability} is a function $p_t(\cdot, \cdot): \mbb{R} \times \mbb{R} \mapsto \mbb{R}$ such that 

    \begin{equation*}
        \Prob[X(t) \in A | X(0) = x] = \int_A p_t(x,y) \dif y
    \end{equation*}
\end{definition}

\begin{theorem}[The Chapman-Kolmogorov Equation]
    The Markov property and homogeneity implies the \textbf{Chapman-Kolmogorov equation} 

    \begin{equation*}
        p_{t+u}(x, y) = \int_\mbb{R} p_t(x, z) p_u(z, y) \dif z.
    \end{equation*}
\end{theorem}

\subsection{Jump Processes}

\begin{definition}[Jump Processes]
    $\{X(t): t \in \}$ is a \textbf{jump process} if 
    
    \begin{itemize}
        \item there is a \textbf{jump rate density} $r(x,y)$ with the \textbf{exit rate} 

        \begin{equation*}
            R(x) = \int_\mbb{R} r(x,y) \dif y \le M < \infty, \; \forall x \in \mbb{R},
        \end{equation*}
    
        where $M \in \mbb{R}$ is a constant;

        \item its transition density satisfies 
        
        \begin{equation*}
            p_{\Delta t}(x, y) = r(x, y) \Delta t + \left( 1 - R(x) \Delta t \right) \delta(y - x) + o(\Delta t), \; \text{as} \, \Delta t \to 0.
        \end{equation*}
    \end{itemize}
\end{definition}

\begin{theorem}[The Kolmogorov-Feller Equation]
    The Chapman-Kolmogorov equation of a jump process turns into the \textbf{Kolmogorov-Feller equation} for initial condition $x \in \mbb{R}$

    \begin{equation*}
        \frac{\partial}{\partial t} p_t(x, y) = \int_\mbb{R} p_t(x, z) r(z, y) - p_t(x, y) r(y, z)\dif z
    \end{equation*}
\end{theorem}

\subsection{Diffusion Processes}

\begin{definition}[The Brownian Motion]
    The \textbf{Brownian motion} is a Gaussian process $B: \mbb{R}_+ \mapsto \mbb{R}$ with $m(t) = 0$ and $c(t, t') = \min (t, t')$ and almost surely continuous paths.
\end{definition}

\begin{proposition}[Brownian Motions are Markov]
    A Brownian motion is Markov, and it has independent increments: $\forall t_1 < \cdots < t_n$, $(X(t_{k+1}) - X_{t_k})_{k = 1, \cdots, n-1}$ are independent variables. 
\end{proposition}

\begin{proposition}[Brownian Motions are Homeogeneous]
    Furthermore, the increments are stationary: $X(t) - X(s)$ and $X(t-s) - X(0) = X(t-s)$ have the same distribution, for $t \> s$. So $B(t)$ is homoegeneous.
\end{proposition}

\begin{remark}
    $B(t)$ is not stationary.
\end{remark}

\begin{proposition}
    The transition density $p_t(x,y)$ of a Brownian motion is a Gaussian PDF with mean $y-x$ and variance $t$, which satisfies the heat equation (or diffusion equation): 

    \begin{equation*}
        \frac{\partial p_t}{\partial t} = \frac{1}{2} \frac{\partial^2 p_t}{\partial y^2}
    \end{equation*}

    with the initial condition $p_0(x, y) = \delta(y - x)$.
\end{proposition}

\begin{proposition}
    Brownian motions are normally distributed: $B(t) \sim \mathcal{N}(0, t)$.
\end{proposition}

\begin{proposition}
    $B(t)$ is scale-invariant: $B(\lambda t)$ and $\sqrt{\lambda} B(t)$ have the same distribution. 
\end{proposition}

\begin{proposition}
    $B(t)$ is almost surely continuous, but it is also almost surely nowhere differentiable. Actually, 

    \begin{equation*}
        \xi_{t, h} := \frac{B(t+h) - B(t)}{h} \sim \mathcal{N}\left(0, \frac{1}{h}\right).
    \end{equation*}
\end{proposition}

Although Brownian motions are almost surely nowhere differentiable, we can still informally talk about the limit proecss $\xi_t := \lim\limits_{h \to 0} \xi_{t, h}$. 

\begin{definition}[Gaussian White Noises]
    $\xi_t := \lim\limits_{h \to 0} \xi_{t, h}$ is called the \textbf{Gaussian white noise}.
\end{definition}

\begin{remark}
    The Gaussian white noise can be considered as a limiting case of a Gaussian process with mean $m(t) = 0$ and $c(t, t') = \delta(t - t')$.
\end{remark}

\begin{proposition}
    $B(t) = \int_0^t \xi_{t'} \dif t'$, or we can write it as a Stochastic differential equation 

    \begin{equation*}
        \frac{\dif B}{\dif t} = \xi, 
    \end{equation*}

    with $B(0) = 0$.
\end{proposition}